# Association-Rule-Mining-GPU-vs-CPU

## Project Requirements
In this project you will learn to program, analyze and evaluate 2 different classes of Parallel Machines - shared memory multiprocessors and GPUs.  Specifically you will be using (i) ladon.cse.psu.edu for the former which has 48 cores and 64GB of physical memory; and (ii) W135 workstations which are equipped with an NVidia Quadro K2200 (Maxwell) card.

 

Application: In this project, you will focus on the Association Rule Mining problem that has been discussed in class. Please note that there may be public domain versions of this code (shared memory and GPU) on the Internet. You are NOT supposed to consult and/or borrow any such code for this project. Such actions will be considered as Academic Integrity violations and will be dealt with severely.  From the sketch of the implementation discussed in class,  go through the Decomposition, Assignment, and Orchestration stages for both hardware platforms, before translating them into code. Performance and scalability are important goals, and simple functional working is not sufficient. You will also need to consider different problem sets/sizes (number of items, number of transactions, skewness of data, etc) and how they scale with the number of processors being used in the platform. The more application parameters (number of transactions, number of items, skewness of item popularity, criteria for considering itemsets as being large, etc.) that you consider and evaluate, the more extensive will be your evaluation.

Hardware Platforms: You will use "ladon" and "W135 (accessible as e5-cse-135-xx.cse.psu.edu where you replace xx with machine number)" machines in CSE for your application development, debugging and evaluations. In the former, you can use the pthread libraries to implement the shared memory version, together with its thread control and synchronization routines. On the GPU platform, you can use CUDA (https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf (Links to an external site.)) for your implementation. 

Evaluation: You should conduct detailed evaluations of both raw performance, as well as scalability metrics - varying number of processors, application parameters, etc. You should be able to demonstrate how well your application scales on each platform, together with identifying/quantifying the factors - whether application parameters such as serial fraction and/or hardware bottlenecks - that impact its scalability. You should point to specific phases of the application whose scalability becomes a problem, and be able to point out software/hardware reasons for these problems. Finally, you should also COMPARE and CONTRAST, the programming ease, and performance/scalability comparisons between the shared memory and GPU platforms.  Please be aware that there may be other users on these systems concurrently. So your performance measurements should be congnizant of those factors requiring evaluations during periods of idleness and/or repetitive experiments to eliminate vagaries due to such multitasking.

You will work in teams of 2. You are free to form your own teams, but let the instructor know at the earliest.  Work division between team members should be relatively uniform, with all team members understanding the entire implementation on both platforms rather than just the piece they worked on. As stated above, it is important that each team does this project individually and NOT resort to any form of academic misconduct/violations.

At the end of the project, you need to submit a detailed report describing your implementation on both platforms, and the outcomes from your implementation/evaluation exercises. 
